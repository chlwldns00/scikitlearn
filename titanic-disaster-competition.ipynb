{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n%matplotlib inline \n#notebook을 실행한 브라우저에서 바로 시각화 자료를 볼수있게 함\n\ntitanic_df = pd.read_csv('/kaggle/input/titanic/train.csv') #같은 디렉토리안의 train.csv 파일을 df형식으로 읽어와서 객체 생성\ntitanic_df.head(3) #상위 3개의 row만 뽑아옴","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(titanic_df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_df.describe().transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('결측지 처리전 데이터 세트 Null 값 갯수 \\n',titanic_df.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True) #inplace 파라미터 True ->적용한것을 바로 반환\ntitanic_df['Cabin'].fillna('N', inplace=True) \ntitanic_df['Embarked'].fillna('N', inplace=True)\nprint('결측지 처리후 데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 학습 및 예측에  불필요한 피처들 제거\ndef drop_features(df):\n    df.drop(['Name','Ticket'], axis=1, inplace=True)\n    return df\n\n# 레이블 인코딩 수행. \ndef format_features(df):\n    df['Cabin'] = df['Cabin'].str[:1]\n    features = ['Cabin','Sex','Embarked']\n    for feature in features:\n        le = LabelEncoder()\n        le = le.fit(df[feature])\n        df[feature] = le.transform(df[feature])\n    return df\n\n# 데이터 전처리 함수 정의\ndef transform_features(df):\n    df = drop_features(df)\n    df = format_features(df)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_titanic_df = titanic_df['Survived']\nX_titanic_df = titanic_df.drop('Survived',axis=1, inplace=False)\nX_titanic_df = transform_features(X_titanic_df) #전처리 적용\nX_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n                                                  test_size=0.2, random_state=11)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data=pd.read_csv('/kaggle/input/titanic/test.csv')\n\ntest_data=transform_features(test_data)\ntest_data['Age'].fillna(test_data['Age'].mean(), inplace=True) #inplace 파라미터 True ->적용한것을 바로 반환\ntest_data['Cabin'].fillna('N', inplace=True) \ntest_data['Embarked'].fillna('N', inplace=True)\ntest_data.dropna(inplace=True)\ntest_data.loc[418]=[1310,3,1,30.27259,1,1,22.3583,7,0]\ntest_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\ndt_clf = DecisionTreeClassifier(random_state=11)\nrf_clf = RandomForestClassifier(random_state=11)\nlr_clf = LogisticRegression(solver='liblinear')\n\n# DecisionTreeClassifier 학습/예측/평가\ndt_clf.fit(X_train , y_train)\ndt_pred = dt_clf.predict(X_test)\nprint('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n\n# RandomForestClassifier 학습/예측/평가\nrf_clf.fit(X_train , y_train)\nrf_pred = rf_clf.predict(X_test)\nprint('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n\n# LogisticRegression 학습/예측/평가\nlr_clf.fit(X_train , y_train)\nlr_pred = lr_clf.predict(X_test)\nprint('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(dt_clf, X_titanic_df , y_titanic_df , cv=5)\nfor iter_count,accuracy in enumerate(scores):\n    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n\nprint(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {'max_depth':[2,3,5,10],\n             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]} #파라미터 설정\n\ngrid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5) #의사결정나무 모델로 GridSearchCV 적용\n\ngrid_dclf.fit(X_train, y_train)\n\nprint('GridSearchCV 최적 하이퍼 파라미터 :', grid_dclf.best_params_)\nprint('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\nbest_dclf = grid_dclf.best_estimator_\n\n\n# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \ndpredictions = best_dclf.predict(test_data)\nmy_first_submission = pd.DataFrame({\"PassengerId\": test_data.PassengerId, \"Survived\": dpredictions})\nmy_first_submission.to_csv(\"my_first_submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dpredictions\nlen(dpredictions)\n#test_prediction=best_dclf.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}